{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CrossSection Notebook Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be latest CrossSection notebook, and a combination of CrossSection_notebook_v5 and CrossSection Post 3D v4\n",
    "\n",
    "This notebook is for pre-processing only, as it may be running for some time multiprocessing different cross section cuts\n",
    "\n",
    "TAG 28.02.20\n",
    "- Updated with possibility to extract every n'th increment\n",
    "- Updated to Python 3\n",
    "\n",
    "OBS: When running models with beams (and el type 52), search_elem_v42f_multi_test2 could possibly be used instead to get rid of bug (and possibly introduce others - so use with caution and only for information!)\n",
    "\n",
    "\n",
    "TAG 24.06.20\n",
    "- Updated with release of search_elem_v42\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-28T13:12:34.846775Z",
     "start_time": "2020-02-28T13:12:34.842784Z"
    }
   },
   "source": [
    "## Import and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T12:35:24.631091Z",
     "start_time": "2022-05-05T12:35:23.101697Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing py_post: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13968/3557121363.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr'C:\\git\\marc_tools'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msearch_elem_v45f_multi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\git\\marc-tools\\search_elem_v45f_multi.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr'C:\\Scripts'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpy_post\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mheapq\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnsmallest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing py_post: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import ipywidgets\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, r'C:\\git\\marc_tools')\n",
    "import search_elem_v45f_multi as cs\n",
    "import re\n",
    "import pathlib\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, clear_output, HTML\n",
    "from ipywidgets import widgets, Layout\n",
    "\n",
    "# increase width of screen\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:76% !important; }</style>\"))\n",
    "\n",
    "\n",
    "# Common functions for pre- and post-processing\n",
    "def find_files(run_dir, *args):\n",
    "    '''\n",
    "    Function that finds all files with specified ending\n",
    "    \n",
    "    :param run_dir: Directory containing files\n",
    "    :param args: Arguments which run_dir must contain\n",
    "    \n",
    "    :return files: Files containing arguments\n",
    "\n",
    "    '''\n",
    "    file_paths = sorted(run_dir.rglob(f'*{args[-1]}*'))\n",
    "    files = [p.relative_to(run_dir) for p in file_paths]\n",
    "\n",
    "    for arg in args[:-1]:\n",
    "        files = [f for f in files if arg.lower() in str(f).lower()]\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def check_complete(folder, sts_files):\n",
    "    success_files = []\n",
    "    \n",
    "    for sts in sts_files:\n",
    "        with open(os.path.join(folder, sts), 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                if 'Job ends with exit number :    3004' in line:\n",
    "                    success_files.append(sts)\n",
    "    \n",
    "    return success_files\n",
    "\n",
    "def filter_list(my_list, filter_strings):\n",
    "    for f in filter_strings:\n",
    "        my_list = [l for l in my_list if f not in l]\n",
    "    \n",
    "    return my_list\n",
    "\n",
    "def get_max_min(df, get):\n",
    "    \n",
    "    if get.lower() == 'max':\n",
    "        val_loc = list(df.max()).index(max(df.max()))\n",
    "    elif get.lower() == 'min':\n",
    "        val_loc = list(df.min()).index(min(df.min()))\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    val_name = df.columns[val_loc].split('.')[0]\n",
    "    return_df = df.iloc[:, val_loc]\n",
    "    \n",
    "    return val_name, return_df\n",
    "      \n",
    "def remove_after(var, symbol):\n",
    "    if symbol in var:\n",
    "        var_split = var.split(symbol)\n",
    "        var = symbol.join(var_split[:-1])\n",
    "    return var\n",
    "\n",
    "def rename_cols(columns):\n",
    "    rename_cols = {}\n",
    "    for col in columns:\n",
    "        col_val = col.replace(title, '').replace('.', '')\n",
    "        try:\n",
    "            col_val = int(col_val) + 1\n",
    "        except ValueError:\n",
    "            if col_val == '':\n",
    "                col_val = 1\n",
    "            else:\n",
    "                pass\n",
    "        rename_cols[col] = col_val\n",
    "    return rename_cols\n",
    "\n",
    "\n",
    "def read_cs_input(input_file):\n",
    "    '''\n",
    "    TODO: Find out what to do if several excel sheets - currently returns last sheet\n",
    "    '''\n",
    "    fi = str(input_file)\n",
    "    if fi.endswith('.xlsx'):\n",
    "        xl = pd.ExcelFile(excel_dir)\n",
    "\n",
    "        for sheet in xl.sheet_names:\n",
    "            dfn = xl.parse(sheet)\n",
    "        \n",
    "        # OBS: Returns last sheet!\n",
    "        return dfn\n",
    "    \n",
    "    elif fi.endswith('.csv'):\n",
    "        # Post-process csv\n",
    "        return ''\n",
    "    else:\n",
    "        print(f'Check that {fi} is excel- (.xlsx) or csv-file (.csv)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing py_post: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25576/65594622.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr'C:\\git\\marc_tools'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpy_post\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing py_post: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'C:\\git\\marc_tools')\n",
    "import py_post\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T12:35:32.985805Z",
     "start_time": "2022-05-05T12:35:32.966824Z"
    }
   },
   "outputs": [],
   "source": [
    "# Input\n",
    "project = r'1978_BP_Tortue_EF_Torque\\Phase1'\n",
    "run = 'Analysis'\n",
    "\n",
    "nskip = 2 # skips every nskip'th increment - Should be 0?\n",
    "\n",
    "# Testing purposes\n",
    "# project = r'FEM\\FE_checks'\n",
    "# run = 'Element_type_ring_stiffness'\n",
    "\n",
    "# CS Input\n",
    "dimension = '3D'\n",
    "\n",
    "# Establishing directories\n",
    "project_folder = pathlib.Path(r'D:/Projects', project)\n",
    "run_folder = project_folder / run\n",
    "\n",
    "# Calculate plastic strain ?\n",
    "calcPl = 0\n",
    "\n",
    "# Manipulate curvature calculation? default = '' (0.5)\n",
    "DiamTol = '0.5'\n",
    "\n",
    "# CrossSection\n",
    "cb = elsetl = nodF = tenCB = ''\n",
    "si = sym = stressT = refLc = nas = immRem = 0\n",
    "txt = 1\n",
    "refL1 = 2\n",
    "var_list = []\n",
    "\n",
    "# Set dimension\n",
    "if dimension.lower() == 'axi':\n",
    "    extp = 2 # = linear\n",
    "elif dimension.lower() == '3d':\n",
    "    extp = 3 # = combined\n",
    "else:\n",
    "    print('Dimension {} is invalid!'.format(dimension))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-05T12:35:37.231555Z",
     "start_time": "2022-05-05T12:35:37.119655Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# input\n",
    "# model_name = 'Balder_2p_t' # only models containing this name\n",
    "model_name = 'Full_t1'\n",
    "filter_strings = ['Old'] # names that files should not contain\n",
    "\n",
    "post_nodes = {'Full_t12' : 'full_nodes.txt',\n",
    "              'Full_t13' : 'full_nodes.txt',\n",
    "             } # note that these files should be in 'folder'\n",
    "# {'models containing this string' : 'should use this file'}\n",
    "\n",
    "# find all relevant files\n",
    "dat_files = find_files(run_folder, model_name, '.dat')\n",
    "t16_files = find_files(run_folder, model_name, '.t16')\n",
    "sts_files = find_files(run_folder, model_name, '.sts')\n",
    "\n",
    "# filter out cases containing specific strings\n",
    "load_cases = [l for l in t16_files if not any(f in str(l) for f in filter_strings)]\n",
    "cases = [l.parent / l.stem for l in load_cases]\n",
    "dat_cases = [l for l in dat_files if not any(f in str(l) for f in filter_strings)]\n",
    "dat = [l.parent / l.stem for l in dat_cases]\n",
    "# cases = [l.stem for l in load_cases] NEW\n",
    "\n",
    "# Find csv files that exists (not necessarily run)\n",
    "sorted_csv = {}\n",
    "csv_files = list(run_folder.rglob('*cb.csv'))\n",
    "\n",
    "# Sort csv so that csv-files are tied to correct model\n",
    "for csv_file in csv_files:\n",
    "    csv_info = csv_file.name.rpartition('_')\n",
    "    model, csv = csv_info[0], csv_info[2]\n",
    "    \n",
    "    # Check if empty\n",
    "    csv_file_dir = run_folder / csv_file\n",
    "    if csv_file_dir.stat().st_size != 0:\n",
    "    \n",
    "        if model not in sorted_csv.keys():\n",
    "            sorted_csv[model] = [csv]\n",
    "        else:\n",
    "            sorted_csv[model].append(csv)\n",
    "\n",
    "completed = list(sorted_csv.keys())\n",
    "not_completed = [c for c in cases if c.stem not in completed]\n",
    "\n",
    "# Creating widgets to selected load cases to run\n",
    "load_cases = widgets.SelectMultiple(options = dat, value = dat, disable = False, \n",
    "                                    rows = len(cases), layout = Layout(width = '50%'))\n",
    "# wg_dat = widgets.SelectMultiple(options = dat, value = dat, disable = False, \n",
    "#                                     rows = len(cases), layout = Layout(width = '50%'))\n",
    "run_button = widgets.Button(description='Run CrossSection on below cases', layout=Layout(width = '50%'))\n",
    "info_button = widgets.Button(description='CrossSection is completed on these cases', layout=Layout(width = '50%'))\n",
    "\n",
    "# style\n",
    "info_button.style.button_color='#23DFAC'\n",
    "run_button.style.button_color='#f78585'\n",
    "\n",
    "ui_over = widgets.HBox([run_button, info_button])\n",
    "ui_under = widgets.HBox([load_cases])\n",
    "\n",
    "def run_on_click_pre(a):\n",
    "    var_list = []\n",
    "#     sleep_seconds = 6*60*60\n",
    "#     time.sleep(sleep_seconds)\n",
    "    for case in load_cases.value:\n",
    "        \n",
    "        # find box tolerance\n",
    "        case_file = run_folder / case.with_suffix('.sts')\n",
    "        df = pd.read_csv(case_file, skiprows=9, skipfooter=4, \n",
    "                         header=None, sep='\\s+', engine='python') # TODO: Fix NAN\n",
    "        boxTol = max(df.values[:,-1]) + 1\n",
    "        \n",
    "        # make dat and .t16 file directory\n",
    "        dat_file = run_folder / case.with_suffix('.dat')\n",
    "        t16_file = run_folder / case.with_suffix('.t16')\n",
    "        \n",
    "        # find node file for the case - first match in post_node dictionary\n",
    "        for key, value in post_nodes.items():\n",
    "            if key.lower() in str(case).lower():\n",
    "                node_file = run_folder / value\n",
    "                continue\n",
    "        \n",
    "#         if not os.path.isfile(node_file):\n",
    "#             print('Node file does not match')\n",
    "        \n",
    "        # create variable list for post_cases and nodes in node_file\n",
    "        with node_file.open('r') as f:\n",
    "            for line in f:\n",
    "                # Read nodes from file\n",
    "                nodes = re.findall(r'\\d+', line)\n",
    "                [n1, n2, n3, n4] = [int(i) for i in nodes] + ['']*(4-len(nodes))\n",
    "                \n",
    "                # Check if file exists - skip if it does!\n",
    "                var = [str(dat_file),str(t16_file),n1,n2,n3,n4,'','',si,txt,extp,sym,stressT,elsetl,refL1,refLc,nas,tenCB,boxTol,immRem,calcPl,DiamTol,nskip]\n",
    "                if case in sorted_csv.keys():\n",
    "                    if str(n1) not in [re.findall(r'\\d+', n)[0] for n in sorted_csv[case]]:\n",
    "                        var_list.append(var)\n",
    "                else:\n",
    "                    var_list.append(var)\n",
    "                    \n",
    "#     print(var_list)\n",
    "    # create pool and progress bar\n",
    "    pool = mp.Pool(processes=9)\n",
    "#     for _ in tqdm.tqdm_notebook(pool.imap_unordered(cs.search_elem, var_list), total=len(var_list)):\n",
    "    for _ in tqdm(pool.imap_unordered(cs.search_elem, var_list), total=len(var_list)):\n",
    "        pass\n",
    "    pool.terminate()\n",
    "    pool.join()\n",
    "    \n",
    "    \n",
    "display(ui_over, ui_under)\n",
    "run_button.on_click(run_on_click_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "cfc0a2758e33c1d99404bebd88dd22b315af275b12c244f9059b22db3b977d02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
